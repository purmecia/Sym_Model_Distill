{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import process_dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'bert_critic.model'\n",
    "\n",
    "critic_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "critic_model = transformers.BertForSequenceClassification.from_pretrained(model_path)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=critic_model, tokenizer=critic_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium',bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('checkpoint-gpt2-medium')\n",
    "naive_generator = pipeline('text-generation',model=gpt_model,tokenizer=gpt_tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_the_best(classifier_results:list, decoded_results:list, only_label=None):\n",
    "    best_index = 0\n",
    "    best = classifier_results[0]\n",
    "    for current_index, result in enumerate(classifier_results):\n",
    "        if result[0]['score'] > best[0]['score']:\n",
    "            if only_label is not None:\n",
    "                if result[0]['label'] == only_label:\n",
    "                    best = result\n",
    "                    best_index = current_index\n",
    "            else:\n",
    "                best = result\n",
    "                best_index = current_index\n",
    "    return decoded_results[best_index], best\n",
    "\n",
    "\n",
    "def inference_with_critic(text, gpt_tokenizer, gpt_model, critic_pipeline, verbose=False, num_beam=8, num_return=5, max_length=120):\n",
    "    inputs = gpt_tokenizer(text, return_tensors=\"pt\")\n",
    "    beam_outputs = gpt_model.to(device='cuda').generate(\n",
    "        inputs['input_ids'].to(device='cuda'), \n",
    "        attention_mask = inputs['attention_mask'].to(device='cuda'),\n",
    "        num_beams = num_beam,\n",
    "        no_repeat_ngram_size = 1,\n",
    "        num_return_sequences = num_return, \n",
    "        early_stopping = False,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id,\n",
    "        eos_token_id=gpt_tokenizer.eos_token_id,\n",
    "        max_length= max_length\n",
    "    )\n",
    "    decoded_results = [gpt_tokenizer.decode(beam_output) for beam_output in beam_outputs]\n",
    "    decoded_results = list(map(lambda x: x.replace(\"<|endoftext|>\", '').strip(), decoded_results))\n",
    "    if verbose:\n",
    "        print(\"====== Generated by GPT: ======\\n\")\n",
    "        pprint(decoded_results)\n",
    "\n",
    "    classifier_results = [classifier(decoded_result) for decoded_result in decoded_results]\n",
    "    if verbose:\n",
    "        print(\"====== Classifier results: ======\\n\")\n",
    "        pprint(classifier_results)\n",
    "    return select_the_best(classifier_results, decoded_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Generated by GPT: ======\n",
      "\n",
      "['PersonX begins to accept PersonY  xIntention’s new relationship is in the '\n",
      " 'best interest of both parties.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new relationship is a good '\n",
      " 'one.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new relationship is a good '\n",
      " 'one.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new relationship is better '\n",
      " 'than the old one.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new friend is accepted by her '\n",
      " 'family and friends.\\n'\n",
      " ' Y has a better relationship with his parents than he did before, despite '\n",
      " 'the fact that they are still fighting over who should take care of him.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new relationship is a good '\n",
      " 'one.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new friend is accepted by her '\n",
      " 'family and friends.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new relationship is a good '\n",
      " 'one.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new friend is a good fit for '\n",
      " 'her.',\n",
      " 'PersonX begins to accept PersonY  xIntention’s new friend is a good fit for '\n",
      " 'her.']\n",
      "====== Classifier results: ======\n",
      "\n",
      "[[{'label': 'LABEL_0', 'score': 0.9995953440666199}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995798468589783}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995798468589783}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995478987693787}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9990058541297913}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995798468589783}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995878338813782}],\n",
      " [{'label': 'LABEL_0', 'score': 0.9995798468589783}],\n",
      " [{'label': 'LABEL_0', 'score': 0.999450147151947}],\n",
      " [{'label': 'LABEL_0', 'score': 0.999450147151947}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('PersonX begins to accept PersonY  xIntention’s new relationship is in the best interest of both parties.',\n",
       " [{'label': 'LABEL_0', 'score': 0.9995953440666199}])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"PersonX begins to accept PersonY  xIntent\"\n",
    "\n",
    "inference_with_critic(text, gpt_tokenizer, gpt_model, classifier, verbose=True, num_beam=10, num_return=10, max_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/mason/.miniconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'PersonX begins to accept PersonY  xIntent  [GEN] to have a friend '}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_generator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(text):\n",
    "    return text.split('\\t')[0].split('\\n')[0].strip()\n",
    "def inference_wrapper(text, gpt_tokenizer, gpt_model, classifier, num_beam=10, num_return=10, max_length=120):\n",
    "    beam_result, result_label = inference_with_critic(text, \n",
    "        gpt_tokenizer, \n",
    "        gpt_model, \n",
    "        classifier, \n",
    "        verbose=False, \n",
    "        num_beam=num_beam, \n",
    "        num_return=num_return, \n",
    "        max_length=max_length\n",
    "        )\n",
    "    \n",
    "    naive_result = naive_generator(text)[0]['generated_text']\n",
    "    return {\"New Result\":trim(beam_result), \"Naive\":trim(naive_result)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/.miniconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/mason/.miniconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'New Result': 'PersonX begins to accept PersonY  xIntention’s new relationship is in the best interest of both parties.',\n",
       " 'Naive': 'PersonX begins to accept PersonY  xIntent  [GEN] to be friends with PersonY'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"PersonX begins to accept PersonY  xIntent\"\n",
    "inference_wrapper(text, gpt_tokenizer, gpt_model, classifier, num_beam=10, num_return=10, max_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(texts:list)->list:\n",
    "    return list(map(lambda x: x.split(\"[GEN]\")[0].strip(), texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output_4000_DT.tsv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    data = list(reader)\n",
    "    data_ = tuple(map(lambda x: x[0].strip(), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PersonX announces the result  xWant  [GEN]',\n",
       " 'PersonX takes a diploma  HinderedBy  [GEN]',\n",
       " 'PersonX is ranting  xEffect  [GEN]',\n",
       " 'PersonX is practicing  xEffect  [GEN]',\n",
       " 'PersonX is the best person for the job  xIntent  [GEN]',\n",
       " 'PersonX visits a new town  xReact  [GEN]',\n",
       " 'PersonX organizes others to work  HinderedBy  [GEN]',\n",
       " 'PersonX informs PersonY about her surprise  xAttr  [GEN]',\n",
       " \"PersonX doesn't kill anyone  xEffect  [GEN]\",\n",
       " 'PersonX seems to hear PersonY  xIntent  [GEN]')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_comparison.tsv', 'w') as f:\n",
    "    f.write('New Result\\tNaive\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 1/200 [00:01<03:35,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  1%|          | 2/200 [00:02<04:49,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  2%|▏         | 3/200 [00:05<07:18,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  2%|▏         | 4/200 [00:07<06:53,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  2%|▎         | 5/200 [00:09<05:54,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  3%|▎         | 6/200 [00:10<05:07,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  4%|▎         | 7/200 [00:13<06:37,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  4%|▍         | 8/200 [00:16<07:36,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  4%|▍         | 9/200 [00:17<06:33,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  5%|▌         | 10/200 [00:20<07:16,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  6%|▌         | 11/200 [00:21<06:05,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  6%|▌         | 12/200 [00:22<04:41,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  6%|▋         | 13/200 [00:24<05:26,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  7%|▋         | 14/200 [00:25<04:48,  1.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  8%|▊         | 15/200 [00:27<04:47,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  8%|▊         | 16/200 [00:28<04:55,  1.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  8%|▊         | 17/200 [00:32<06:23,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  9%|▉         | 18/200 [00:33<05:39,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|▉         | 19/200 [00:36<06:14,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|█         | 20/200 [00:38<06:54,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|█         | 21/200 [00:41<07:00,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 11%|█         | 22/200 [00:42<05:54,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█▏        | 23/200 [00:45<06:54,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█▏        | 24/200 [00:48<07:35,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█▎        | 25/200 [00:50<06:45,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 13%|█▎        | 26/200 [00:53<07:29,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 14%|█▎        | 27/200 [00:56<07:24,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 14%|█▍        | 28/200 [00:59<07:48,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 14%|█▍        | 29/200 [01:01<07:08,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 15%|█▌        | 30/200 [01:02<05:54,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 16%|█▌        | 31/200 [01:04<05:43,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 16%|█▌        | 32/200 [01:07<06:19,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 16%|█▋        | 33/200 [01:10<07:00,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 17%|█▋        | 34/200 [01:11<06:00,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 35/200 [01:14<06:44,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 36/200 [01:17<07:15,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 37/200 [01:20<07:34,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 19%|█▉        | 38/200 [01:21<05:54,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|█▉        | 39/200 [01:23<05:52,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|██        | 40/200 [01:25<05:41,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|██        | 41/200 [01:27<05:18,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 21%|██        | 42/200 [01:29<04:56,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 22%|██▏       | 43/200 [01:32<05:55,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 22%|██▏       | 44/200 [01:35<06:39,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 22%|██▎       | 45/200 [01:36<05:40,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 23%|██▎       | 46/200 [01:38<05:13,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 24%|██▎       | 47/200 [01:40<05:08,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 24%|██▍       | 48/200 [01:42<04:48,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 24%|██▍       | 49/200 [01:43<04:24,  1.75s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██▌       | 50/200 [01:44<04:02,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 26%|██▌       | 51/200 [01:46<03:43,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 26%|██▌       | 52/200 [01:49<04:53,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 26%|██▋       | 53/200 [01:50<04:16,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 27%|██▋       | 54/200 [01:51<03:49,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 55/200 [01:53<03:59,  1.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 56/200 [01:55<04:07,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 57/200 [01:57<04:37,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 29%|██▉       | 58/200 [02:00<05:29,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 30%|██▉       | 59/200 [02:02<04:52,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 30%|███       | 60/200 [02:03<04:15,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 30%|███       | 61/200 [02:05<03:54,  1.69s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 31%|███       | 62/200 [02:06<03:44,  1.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 32%|███▏      | 63/200 [02:08<04:00,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 32%|███▏      | 64/200 [02:09<03:05,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 32%|███▎      | 65/200 [02:10<03:15,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 33%|███▎      | 66/200 [02:11<02:57,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 34%|███▎      | 67/200 [02:13<03:13,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 34%|███▍      | 68/200 [02:14<03:10,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 34%|███▍      | 69/200 [02:16<03:14,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 35%|███▌      | 70/200 [02:18<03:29,  1.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 36%|███▌      | 71/200 [02:20<03:42,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 36%|███▌      | 72/200 [02:21<03:05,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 36%|███▋      | 73/200 [02:22<02:47,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 37%|███▋      | 74/200 [02:23<02:38,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███▊      | 75/200 [02:26<03:49,  1.83s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███▊      | 76/200 [02:28<03:47,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███▊      | 77/200 [02:29<03:33,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 39%|███▉      | 78/200 [02:30<02:59,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|███▉      | 79/200 [02:32<03:01,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|████      | 80/200 [02:34<03:38,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|████      | 81/200 [02:37<04:21,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 41%|████      | 82/200 [02:39<03:55,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 42%|████▏     | 83/200 [02:41<04:02,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 42%|████▏     | 84/200 [02:42<03:30,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 42%|████▎     | 85/200 [02:44<03:08,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 43%|████▎     | 86/200 [02:46<03:26,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 44%|████▎     | 87/200 [02:47<03:12,  1.71s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 44%|████▍     | 88/200 [02:51<04:03,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 44%|████▍     | 89/200 [02:52<03:48,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 45%|████▌     | 90/200 [02:54<03:33,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 46%|████▌     | 91/200 [02:55<02:57,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 46%|████▌     | 92/200 [02:58<03:43,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 46%|████▋     | 93/200 [03:01<04:16,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 47%|████▋     | 94/200 [03:04<04:39,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 48%|████▊     | 95/200 [03:06<04:00,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 48%|████▊     | 96/200 [03:07<03:28,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 48%|████▊     | 97/200 [03:08<02:57,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 49%|████▉     | 98/200 [03:10<02:40,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|████▉     | 99/200 [03:12<02:59,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████     | 100/200 [03:15<03:39,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████     | 101/200 [03:16<02:52,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 51%|█████     | 102/200 [03:16<02:24,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 52%|█████▏    | 103/200 [03:18<02:27,  1.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 52%|█████▏    | 104/200 [03:19<02:05,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 52%|█████▎    | 105/200 [03:21<02:20,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 53%|█████▎    | 106/200 [03:22<02:18,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 54%|█████▎    | 107/200 [03:25<03:05,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 54%|█████▍    | 108/200 [03:26<02:35,  1.69s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 55%|█████▍    | 109/200 [03:30<03:16,  2.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 55%|█████▌    | 110/200 [03:31<02:42,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 56%|█████▌    | 111/200 [03:33<02:59,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 56%|█████▌    | 112/200 [03:34<02:27,  1.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 56%|█████▋    | 113/200 [03:35<02:04,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 57%|█████▋    | 114/200 [03:36<02:06,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 57%|█████▊    | 115/200 [03:38<01:56,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 58%|█████▊    | 116/200 [03:39<01:57,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 58%|█████▊    | 117/200 [03:42<02:40,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 59%|█████▉    | 118/200 [03:44<02:32,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|█████▉    | 119/200 [03:47<03:03,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|██████    | 120/200 [03:48<02:32,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|██████    | 121/200 [03:49<02:12,  1.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 61%|██████    | 122/200 [03:51<02:13,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▏   | 123/200 [03:52<01:54,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▏   | 124/200 [03:54<02:01,  1.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▎   | 125/200 [03:56<02:03,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 63%|██████▎   | 126/200 [03:57<01:42,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▎   | 127/200 [04:00<02:21,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▍   | 128/200 [04:02<02:17,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▍   | 129/200 [04:05<02:43,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 65%|██████▌   | 130/200 [04:06<02:19,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 66%|██████▌   | 131/200 [04:07<01:57,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 66%|██████▌   | 132/200 [04:10<02:25,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 66%|██████▋   | 133/200 [04:13<02:38,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 67%|██████▋   | 134/200 [04:14<02:10,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 68%|██████▊   | 135/200 [04:16<02:01,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 68%|██████▊   | 136/200 [04:17<01:48,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 68%|██████▊   | 137/200 [04:18<01:21,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 69%|██████▉   | 138/200 [04:19<01:24,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|██████▉   | 139/200 [04:21<01:42,  1.68s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|███████   | 140/200 [04:23<01:43,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|███████   | 141/200 [04:24<01:32,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 71%|███████   | 142/200 [04:27<01:48,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 72%|███████▏  | 143/200 [04:29<01:42,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 72%|███████▏  | 144/200 [04:30<01:36,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 72%|███████▎  | 145/200 [04:31<01:22,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 73%|███████▎  | 146/200 [04:33<01:19,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 74%|███████▎  | 147/200 [04:34<01:11,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 74%|███████▍  | 148/200 [04:35<01:08,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 74%|███████▍  | 149/200 [04:36<01:07,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████▌  | 150/200 [04:39<01:20,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 76%|███████▌  | 151/200 [04:40<01:23,  1.69s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 76%|███████▌  | 152/200 [04:42<01:22,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 76%|███████▋  | 153/200 [04:44<01:23,  1.77s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 77%|███████▋  | 154/200 [04:46<01:26,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 78%|███████▊  | 155/200 [04:48<01:18,  1.75s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 78%|███████▊  | 156/200 [04:49<01:11,  1.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 78%|███████▊  | 157/200 [04:51<01:12,  1.68s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 79%|███████▉  | 158/200 [04:52<01:05,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|███████▉  | 159/200 [04:55<01:14,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|████████  | 160/200 [04:56<01:09,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|████████  | 161/200 [04:58<01:11,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 81%|████████  | 162/200 [05:00<01:06,  1.75s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 82%|████████▏ | 163/200 [05:01<00:58,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 82%|████████▏ | 164/200 [05:03<01:06,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 82%|████████▎ | 165/200 [05:05<00:58,  1.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 83%|████████▎ | 166/200 [05:06<00:53,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 84%|████████▎ | 167/200 [05:09<01:07,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 84%|████████▍ | 168/200 [05:11<01:02,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 84%|████████▍ | 169/200 [05:12<00:53,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 85%|████████▌ | 170/200 [05:13<00:40,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 86%|████████▌ | 171/200 [05:16<00:55,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 86%|████████▌ | 172/200 [05:17<00:51,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 86%|████████▋ | 173/200 [05:21<01:01,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 87%|████████▋ | 174/200 [05:23<01:03,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████▊ | 175/200 [05:24<00:49,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████▊ | 176/200 [05:26<00:48,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████▊ | 177/200 [05:28<00:43,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 89%|████████▉ | 178/200 [05:30<00:40,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|████████▉ | 179/200 [05:32<00:37,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|█████████ | 180/200 [05:33<00:34,  1.71s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|█████████ | 181/200 [05:35<00:32,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 91%|█████████ | 182/200 [05:37<00:32,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 92%|█████████▏| 183/200 [05:39<00:33,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 92%|█████████▏| 184/200 [05:40<00:28,  1.77s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 92%|█████████▎| 185/200 [05:43<00:30,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 93%|█████████▎| 186/200 [05:44<00:24,  1.75s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 94%|█████████▎| 187/200 [05:46<00:22,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 94%|█████████▍| 188/200 [05:47<00:19,  1.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 94%|█████████▍| 189/200 [05:51<00:23,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 95%|█████████▌| 190/200 [05:54<00:24,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 96%|█████████▌| 191/200 [05:56<00:22,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 96%|█████████▌| 192/200 [05:57<00:16,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 96%|█████████▋| 193/200 [05:59<00:12,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 97%|█████████▋| 194/200 [06:02<00:13,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 98%|█████████▊| 195/200 [06:04<00:10,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 98%|█████████▊| 196/200 [06:07<00:09,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 98%|█████████▊| 197/200 [06:10<00:07,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 99%|█████████▉| 198/200 [06:12<00:04,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|█████████▉| 199/200 [06:13<00:02,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████| 200/200 [06:14<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "with open('results_comparison.tsv', 'a') as f:\n",
    "    for text in tqdm(data_[2045:2245]):\n",
    "        result = inference_wrapper(text, gpt_tokenizer, gpt_model, classifier, num_beam=10, num_return=10, max_length=120)\n",
    "        f.write(f\"{result['New Result']}\\t{result['Naive']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e2f23b3d2ec848fdd96546fdcf3cc558c9823e02c22d87422c651f8fba0f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
